# -*- coding: utf-8 -*-
"""model_final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1r4yH9kC3lSEipqOGv2aaJ_JOaigwO_Yz
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.feature_selection import SelectKBest, f_classif
import seaborn as sns
import matplotlib.pyplot as plt
import xgboost as xgb
from collections import Counter

df = pd.read_csv('/content/CVD_Vital_SIgns.csv')

print(df.describe())

print(df.isnull().sum())

df = df.drop_duplicates()

def preprocess_data(df):
  correlation_matrix = df.corr()
  high_corr_pairs = []
  for i in range(len(correlation_matrix.columns)):
      for j in range(i+1, len(correlation_matrix.columns)):
          if abs(correlation_matrix.iloc[i, j]) > 0.95:
              high_corr_pairs.append((correlation_matrix.columns[i], correlation_matrix.columns[j]))

  print(f"\nHighly correlated feature pairs (>0.95): {high_corr_pairs}")
  features_to_remove = []
  for pair in high_corr_pairs:
      if pair[1] not in features_to_remove and pair[1] != 'Label':
          features_to_remove.append(pair[1])

  if features_to_remove:
      print(f"Removing highly correlated features: {features_to_remove}")
      df = df.drop(columns=features_to_remove)
  numeric_cols = df.select_dtypes(include=[np.number]).columns.drop('Label')
  low_variance_cols = []
  for col in numeric_cols:
      if df[col].var() < 0.01:
          low_variance_cols.append(col)

  if low_variance_cols:
      print(f"Removing low variance features: {low_variance_cols}")
      df = df.drop(columns=low_variance_cols)

  return df

df = preprocess_data(df)

X = df.drop('Label', axis=1)
y = df['Label']

class_counts = y.value_counts()
imbalance_ratio = class_counts.max() / class_counts.min()
print(f"Imbalance ratio: {imbalance_ratio:.2f}")

scaler = RobustScaler()
X_scaled = scaler.fit_transform(X)
X_scaled = pd.DataFrame(X_scaled, columns=X.columns)

selector = SelectKBest(score_func=f_classif, k=min(10, X_scaled.shape[1]))  # Select top 10 features or all if less
X_selected = selector.fit_transform(X_scaled, y)
selected_features = X.columns[selector.get_support()]

X_train, X_test, y_train, y_test = train_test_split(
    X_selected, y,
    test_size=0.2,
    random_state=42,
    stratify=y
)

rf_regularized = RandomForestClassifier(
    n_estimators=50,
    max_depth=3,
    min_samples_split=10,
    min_samples_leaf=5,
    max_features='sqrt',
    random_state=42,
    class_weight='balanced'
)

rf_regularized.fit(X_train, y_train)
y_pred_rf = rf_regularized.predict(X_test)

rf_train_accuracy = accuracy_score(y_train, rf_regularized.predict(X_train))
rf_test_accuracy = accuracy_score(y_test, y_pred_rf)

print(f"Train accuracy: {rf_train_accuracy:.4f}")
print(f"Test accuracy: {rf_test_accuracy:.4f}")

cm_rf = confusion_matrix(y_test, y_pred_rf)
classification_rep_rf = classification_report(y_test, y_pred_rf)

print(cm_rf)

print(classification_rep_rf)

plt.figure(figsize=(8, 6))
sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues')
plt.title('Random Forest - Confusion Matrix')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.show()

dt_regularized = DecisionTreeClassifier(
    max_depth=3,
    min_samples_split=20,
    min_samples_leaf=10,
    max_features='sqrt',
    random_state=42,
    class_weight='balanced'
)

dt_regularized.fit(X_train, y_train)
y_pred_dt = dt_regularized.predict(X_test)

dt_train_accuracy = accuracy_score(y_train, dt_regularized.predict(X_train))
dt_test_accuracy = accuracy_score(y_test, y_pred_dt)

print(f"Train accuracy: {dt_train_accuracy:.4f}")
print(f"Test accuracy: {dt_test_accuracy:.4f}")

cm_dt = confusion_matrix(y_test, y_pred_dt)
classification_rep_dt = classification_report(y_test, y_pred_dt)

print(cm_dt)

print(classification_rep_dt)

plt.figure(figsize=(8, 6))
sns.heatmap(cm_dt, annot=True, fmt='d', cmap='Blues')
plt.title('Decision Tree - Confusion Matrix')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.show()

